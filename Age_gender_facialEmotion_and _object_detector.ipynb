{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qQqXeDWFHUl-"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9dlYWXrDI9LL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Model 00000226B93158B0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_classifier=cv2.CascadeClassifier('C:\\\\Users\\\\sahay\\\\OneDrive\\\\Desktop\\\\opencv\\data\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "emotion_model = load_model('C:\\\\Users\\\\sahay\\\\OneDrive\\\\Desktop\\\\Final_Assignment\\\\facial_emotion\\\\emotion_detection.h5')\n",
    "age_model = load_model('C:\\\\Users\\\\sahay\\\\OneDrive\\\\Desktop\\\\Final_Assignment\\\\age_gender\\\\age_model.h5')\n",
    "gender_model = load_model('C:\\\\Users\\\\sahay\\\\OneDrive\\\\Desktop\\\\Final_Assignment\\\\age_gender\\\\gender_model.h5')\n",
    "configPath ='C:\\\\Users\\\\sahay\\\\OneDrive\\\\Desktop\\\\Final_Assignment\\\\object_detection\\\\ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'C:\\\\Users\\\\sahay\\\\OneDrive\\\\Desktop\\\\Final_Assignment\\\\object_detection\\\\frozen_inference_graph.pb' \n",
    "object_model = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "object_model.setInputSize(320,320)\n",
    "object_model.setInputScale(1.0/ 127.5)\n",
    "object_model.setInputMean ((127.5, 127.5, 127.5))\n",
    "object_model.setInputSwapRB (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GDVDNDEfJW2O"
   },
   "outputs": [],
   "source": [
    "class_labels=['Angry','Disgust', 'Fear', 'Happy','Neutral','Sad','Surprise']\n",
    "gender_labels = ['Male', 'Female']\n",
    "objct_class_names= ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', \n",
    "                     'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', \n",
    "                     'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', \n",
    "                     'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', \n",
    "                     'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', \n",
    "                     'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', \n",
    "                     'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', \n",
    "                     'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "                     'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', \n",
    "                     'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', \n",
    "                     'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
    "                     'hair drier', 'toothbrush', 'hair brush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press q to exit from the real time live stream window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "QV_JsfarJdpq",
    "outputId": "fb809e8b-ea00-4738-80f0-55d69b9474bb"
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    labels=[]\n",
    "    \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    classIds, confs, bbox = object_model.detect(frame,confThreshold=0.5) \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('o'):\n",
    "        if len(classIds) != 0:\n",
    "            \n",
    "            #object detection\n",
    "           for classId, confidence, box in zip(classIds.flatten(),confs.flatten(), bbox):\n",
    "              cv2.rectangle(frame,box,color=(0,255,0), thickness=2)\n",
    "              cv2.putText(frame,objct_class_names[classId-1].upper(),(box[0]+10, box[1]+30),\n",
    "                          cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    else:\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            roi_gray=gray[y:y+h,x:x+w]\n",
    "            roi_gray=cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            #Get image ready for prediction\n",
    "            roi=roi_gray.astype('float')/255  \n",
    "            roi=img_to_array(roi)\n",
    "            roi=np.expand_dims(roi,axis=0)\n",
    "\n",
    "            #Facial Emotion\n",
    "            preds=emotion_model.predict(roi)[0]  \n",
    "            label=class_labels[preds.argmax()]  \n",
    "            label_position=(x+h,y+25)\n",
    "            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "\n",
    "            #Gender\n",
    "            roi_color=frame[y:y+h,x:x+w]\n",
    "            roi_color=cv2.resize(roi_color,(200,200),interpolation=cv2.INTER_AREA)\n",
    "            gender_predict = gender_model.predict(np.array(roi_color).reshape(-1,200,200,3))\n",
    "            gender_predict = (gender_predict>= 0.5).astype(int)[:,0]\n",
    "            gender_label=gender_labels[gender_predict[0]] \n",
    "            gender_label_position=(x+h,y+55) \n",
    "            cv2.putText(frame,gender_label,gender_label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "\n",
    "            #Age\n",
    "            age_predict = age_model.predict(np.array(roi_color).reshape(-1,200,200,3))\n",
    "            age = round(age_predict[0,0])\n",
    "            age_label_position=(x+h,y+85)\n",
    "            cv2.putText(frame,str(age),age_label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        \n",
    "   \n",
    "    cv2.imshow('Object,Age,Gender and Emotion Detector', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ff.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
